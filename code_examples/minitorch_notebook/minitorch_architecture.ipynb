{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "15_DC_j_KVWI"
      },
      "outputs": [],
      "source": [
        "import minitorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0inD-mEqKwgv"
      },
      "source": [
        "## Go Through Minitorch\n",
        "\n",
        "This is a high level abstraction of some basic components in MiniTorch.\n",
        "\n",
        "<img src=\"../imgs/high_level_abstraction.png\"></img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vmds3l9Kwgv"
      },
      "source": [
        "`class Parameter` is a very important component defined in `class Module`. What the models are learing is actually these `Parameter`(s). Optimizers also look for these parameters and update them following the weight updating rules. See `minitorch/module.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9ics4O5_Kwgw"
      },
      "outputs": [],
      "source": [
        "from typing import Any, Dict, Optional, Sequence, Tuple\n",
        "\n",
        "class Parameter:\n",
        "    \"\"\"\n",
        "    A Parameter is a special container stored in a `Module`.\n",
        "\n",
        "    It is designed to hold a `Variable`, but we allow it to hold\n",
        "    any value for testing.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, x: Any, name: Optional[str] = None) -> None:\n",
        "        self.value = x\n",
        "        self.name = name\n",
        "        if hasattr(x, \"requires_grad_\"):\n",
        "            self.value.requires_grad_(True)\n",
        "            if self.name:\n",
        "                self.value.name = self.name\n",
        "\n",
        "    def update(self, x: Any) -> None:\n",
        "        \"Update the parameter value.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4WS47_bfKwgw"
      },
      "outputs": [],
      "source": [
        "class Module:\n",
        "    \"\"\"\n",
        "    Modules form a tree that store parameters and other\n",
        "    submodules. They make up the basis of neural network stacks.\n",
        "\n",
        "    Attributes:\n",
        "        _modules : Storage of the child modules\n",
        "        _parameters : Storage of the module's parameters\n",
        "        training : Whether the module is in training mode or evaluation mode\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    _modules: Dict[str, 'Module']\n",
        "    _parameters: Dict[str, Parameter]\n",
        "    training: bool\n",
        "\n",
        "    def parameters(self) -> Sequence[Parameter]:\n",
        "        \"Enumerate over all the parameters of this module and its descendents.\"\n",
        "        return [j for _, j in self.named_parameters()]\n",
        "\n",
        "    def __call__(self, *args: Any, **kwargs: Any) -> Any:\n",
        "        return self.forward(*args, **kwargs)\n",
        "\n",
        "    def train(self) -> None:\n",
        "        \"Set the mode of this module and all descendent modules to `train`.\"\n",
        "        for m in self.modules():\n",
        "            m.train()\n",
        "        self.training = True\n",
        "\n",
        "    def eval(self) -> None:\n",
        "        \"Set the mode of this module and all descendent modules to `eval`.\"\n",
        "        for m in self.modules():\n",
        "            m.eval()\n",
        "        self.training = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-F0cQT5Kwgx"
      },
      "source": [
        "We define a `RParam` function here to initialize the `Parameter` in `project/run_sentiment.py`. We can define more functions for initialization i.e. [xavier](https://paperswithcode.com/method/xavier-initialization), [kaiming](https://paperswithcode.com/method/he-initialization) and structure them better inside the minitorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8aJUrMzJKwgx"
      },
      "outputs": [],
      "source": [
        "# Initialization\n",
        "def RParam(*shape):\n",
        "    r = 0.1 * (minitorch.rand(shape, backend=BACKEND) - 0.5)\n",
        "    return minitorch.Parameter(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXU-yNXHKwgx"
      },
      "source": [
        "See `minitorch/optim.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5WWvsBvlKwgx"
      },
      "outputs": [],
      "source": [
        "class Optimizer:\n",
        "    def __init__(self, parameters: Sequence[Parameter]):\n",
        "        self.parameters = parameters\n",
        "\n",
        "\n",
        "class SGD(Optimizer):\n",
        "    def __init__(self, parameters: Sequence[Parameter], lr: float = 1.0):\n",
        "        super().__init__(parameters)\n",
        "        self.lr = lr\n",
        "\n",
        "    def step(self) -> None:\n",
        "        for p in self.parameters:\n",
        "            if p.value is None:\n",
        "                continue\n",
        "            elif hasattr(p.value, \"grad\"):\n",
        "                if p.value.grad is not None:\n",
        "                    p.update(p.value - self.lr * p.value.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY_2R1vpKwgy"
      },
      "source": [
        "`class Function` is an abstraction for operators with `forward` and `backward` functions. It represents the kind of computation we perform at each node. See `minitorch/tensor_functions.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Dml5S37PKwgy"
      },
      "outputs": [],
      "source": [
        "from minitorch.autodiff import Context\n",
        "from minitorch.tensor import Tensor\n",
        "\n",
        "class Function:\n",
        "    @classmethod\n",
        "    def _backward(cls, ctx: Context, grad_out: Tensor) -> Tuple[Tensor, ...]:\n",
        "        return wrap_tuple(cls.backward(ctx, grad_out))  # type: ignore\n",
        "\n",
        "    @classmethod\n",
        "    def _forward(cls, ctx: Context, *inps: Tensor) -> Tensor:\n",
        "        return cls.forward(ctx, *inps)  # type: ignore\n",
        "\n",
        "    @classmethod\n",
        "    def apply(cls, *vals: Tensor) -> Tensor:\n",
        "        raw_vals = []\n",
        "        need_grad = False\n",
        "        for v in vals:\n",
        "            if v.requires_grad():\n",
        "                need_grad = True\n",
        "            raw_vals.append(v.detach())\n",
        "\n",
        "        # Create the context.\n",
        "        ctx = Context(not need_grad)\n",
        "\n",
        "        # Call forward with the variables.\n",
        "        c = cls._forward(ctx, *raw_vals)\n",
        "\n",
        "        # Create a new variable from the result with a new history.\n",
        "        back = None\n",
        "        if need_grad:\n",
        "            back = minitorch.History(cls, ctx, vals)\n",
        "        return minitorch.Tensor(c._tensor, back, backend=c.backend)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2qSIpDNBKwgy"
      },
      "outputs": [],
      "source": [
        "class Add(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx: Context, t1: Tensor, t2: Tensor) -> Tensor:\n",
        "        return t1.f.add_zip(t1, t2)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx: Context, grad_output: Tensor) -> Tuple[Tensor, Tensor]:\n",
        "        return grad_output, grad_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnzUZd37Kwgz"
      },
      "source": [
        "`class Tensor` is the basic data structure that handles multidimensioanl arrays. See `minitorch/tensor.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lwcsCJiCKwgz"
      },
      "outputs": [],
      "source": [
        "from minitorch.tensor_ops import TensorBackend\n",
        "from minitorch.tensor import History\n",
        "from minitorch.tensor_data import TensorData\n",
        "\n",
        "class Tensor:\n",
        "    \"\"\"\n",
        "    Tensor is a generalization of Scalar in that it is a Variable that\n",
        "    handles multidimensional arrays.\n",
        "    \"\"\"\n",
        "\n",
        "    backend: TensorBackend\n",
        "    history: Optional[History]\n",
        "    grad: Optional[Tensor]\n",
        "    _tensor: TensorData\n",
        "    unique_id: int\n",
        "    name: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE8y70cPKwgz"
      },
      "source": [
        "## Data Storage and Operators\n",
        "\n",
        "This diagram shows several important components of `class Tensor`, including data storage `class TensorData`, backend `class TensorBackend`, etc. Backend relies on `class TensorOps` to execute the actual computation for different operators. Basic functions are implemented and abstracted by `class Function`.\n",
        "\n",
        "<img src=\"../imgs/data_storage_operators.png\"></img>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0ij11O6_Kwgz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "from typing import Sequence\n",
        "from typing_extensions import TypeAlias\n",
        "\n",
        "Storage: TypeAlias = npt.NDArray[np.float64]\n",
        "OutIndex: TypeAlias = npt.NDArray[np.int32]\n",
        "Index: TypeAlias = npt.NDArray[np.int32]\n",
        "Shape: TypeAlias = npt.NDArray[np.int32]\n",
        "Strides: TypeAlias = npt.NDArray[np.int32]\n",
        "\n",
        "UserIndex: TypeAlias = Sequence[int]\n",
        "UserShape: TypeAlias = Sequence[int]\n",
        "UserStrides: TypeAlias = Sequence[int]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "D6AUI-1zKwg0"
      },
      "outputs": [],
      "source": [
        "class TensorData:\n",
        "    _storage: Storage\n",
        "    _strides: Strides\n",
        "    _shape: Shape\n",
        "    strides: UserStrides\n",
        "    shape: UserShape\n",
        "    dims: int"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOTAukDCKwg0"
      },
      "source": [
        "### Indexing\n",
        "\n",
        "<img src=\"../imgs/strides.png\"></img>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ARtLPu2wKwg1"
      },
      "outputs": [],
      "source": [
        "x = minitorch.tensor([1, 2, 3, 4, 5, 6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHzKqmt7Kwg1",
        "outputId": "b801f608-d7ac-4eb7-c8b8-0de5f0256e1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 2., 3., 4., 5., 6.], dtype=float32)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aflSF5cKwg1",
        "outputId": "d282fec6-3bae-4001-f59d-82cff44b33dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((6,), (1,))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x._tensor.shape, x._tensor.strides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scBtjPIrKwg1",
        "outputId": "4904b673-14d9-483b-8040-0393debbbdce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\n",
              "[\n",
              "\t[1.000000 2.000000 3.000000]\n",
              "\t[4.000000 5.000000 6.000000]]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = minitorch.Tensor.make(\n",
        "    storage=x._tensor._storage,\n",
        "    shape=(2, 3),\n",
        "    strides=(3, 1),\n",
        "    backend=x.backend)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kj3abEVKwg1",
        "outputId": "22b1a0b3-2fe6-466d-933f-fb672df51898"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 2., 3., 4., 5., 6.])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y._tensor._storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNTGvDG10p_g",
        "outputId": "6d10eed0-e258-4fec-c574-7eddf557bce3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((2, 3), (3, 1))"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y._tensor.shape, y._tensor.strides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQEVHr4sKwg1",
        "outputId": "e4b3835f-f3b7-4e66-ff15-e3add2e9468f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y._tensor._storage is x._tensor._storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37Ui7WoAKwg2",
        "outputId": "59d82805-bdad-4856-f7a9-e9a271551487"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\n",
              "[\n",
              "\t[\n",
              "\t\t[1.000000]\n",
              "\t\t[2.000000]]\n",
              "\t[\n",
              "\t\t[3.000000]\n",
              "\t\t[4.000000]]\n",
              "\t[\n",
              "\t\t[5.000000]\n",
              "\t\t[6.000000]]]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z = x.view(3, 2, 1)\n",
        "z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En14LQscKwg2",
        "outputId": "da88f068-3865-48a0-ce9f-e108fdb4ff05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((3, 2, 1), (2, 1, 1))"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z._tensor.shape, z._tensor.strides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4M4-YgfKwg2",
        "outputId": "903d341b-239b-4852-d7b1-6506cea50762"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z._tensor._storage is x._tensor._storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AR9aKBFKwg2",
        "outputId": "5adddc3d-2523-405e-d8be-028f4bc947ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(True, 3, 4.0)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z_index = [1, 1, 0]\n",
        "pos = minitorch.index_to_position(z_index, z._tensor._strides)\n",
        "z[tuple(z_index)] == z._tensor._storage[pos], pos, z[tuple(z_index)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljP7gomHKwg2",
        "outputId": "ef3ae28e-29c8-425e-bd49-31a583ac4357"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 1, 0]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out_index = [0, 0, 0]\n",
        "minitorch.to_index(3, z.shape, out_index)\n",
        "out_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UhJoSReKwg2",
        "outputId": "0ec2a753-846a-42f1-cd91-e2c0caffa5a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3, 1)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "shape = (2, 3)\n",
        "minitorch.strides_from_shape(shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1NGGsctKwg3",
        "outputId": "cd1c6625-5903-4432-92e9-5838ac8f0443"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 1, 1)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "shape = (3, 2, 1)\n",
        "minitorch.strides_from_shape(shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bCK6ZOVKwg3",
        "outputId": "5c60ccb1-252d-47e5-cf98-99e5c83285b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\n",
              "[\n",
              "\t[\n",
              "\t\t[1.000000 3.000000 5.000000]\n",
              "\t\t[2.000000 4.000000 6.000000]]]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p = z.permute(2, 1, 0)\n",
        "p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTYuZRGIKwg3",
        "outputId": "978ba110-c9e2-4f74-fd26-9a5f292c036b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1, 2, 3), (1, 1, 2))"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p._tensor.shape, p._tensor.strides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q28eHbRWKwg3",
        "outputId": "e9070544-09d8-4912-af23-45cc6afe1a84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p._tensor._storage is x._tensor._storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UTlXzH2Kwg3",
        "outputId": "94e8e783-a796-436b-b788-590d932948a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_index = [0, 0, 0]\n",
        "minitorch.to_index(-1, p.shape, p_index)\n",
        "p_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2uQrsMLKwg3",
        "outputId": "fa6640cc-833d-49be-f672-53240a4c0089"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "minitorch.index_to_position(p_index, p._tensor._strides)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipScE_ULKwg4"
      },
      "source": [
        "### Backend & Operators\n",
        "\n",
        "See `minitorch/tensor_ops.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "7QuP88fTKwg4"
      },
      "outputs": [],
      "source": [
        "from typing import Callable, Generic, Iterable, Tuple, TypeVar\n",
        "from minitorch.tensor_ops import MapProto\n",
        "\n",
        "class TensorOps:\n",
        "    @staticmethod\n",
        "    def map(fn: Callable[[float], float]) -> MapProto:\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def zip(fn: Callable[[float, float], float]) -> Callable[[Tensor, Tensor], Tensor]:\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def reduce(\n",
        "        fn: Callable[[float, float], float], start: float = 0.0\n",
        "    ) -> Callable[[Tensor, int], Tensor]:\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def matrix_multiply(a: Tensor, b: Tensor) -> Tensor:\n",
        "        raise NotImplementedError(\"Not implemented in this assignment\")\n",
        "\n",
        "    @staticmethod\n",
        "    def cmap(fn: Callable[[float], float]) -> Callable[[Tensor, Tensor], Tensor]:\n",
        "        pass\n",
        "    cuda = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Es03tJIBKwg4"
      },
      "outputs": [],
      "source": [
        "from minitorch.tensor import operators\n",
        "from typing import Type\n",
        "\n",
        "class TensorBackend:\n",
        "    def __init__(self, ops: Type[TensorOps]):\n",
        "        # Maps\n",
        "        self.neg_map = ops.map(operators.neg)\n",
        "        self.sigmoid_map = ops.map(operators.sigmoid)\n",
        "        self.relu_map = ops.map(operators.relu)\n",
        "        self.log_map = ops.map(operators.log)\n",
        "        self.exp_map = ops.map(operators.exp)\n",
        "        self.id_map = ops.map(operators.id)\n",
        "        self.id_cmap = ops.cmap(operators.id)\n",
        "        self.inv_map = ops.map(operators.inv)\n",
        "\n",
        "        # Zips\n",
        "        self.add_zip = ops.zip(operators.add)\n",
        "        self.mul_zip = ops.zip(operators.mul)\n",
        "        self.lt_zip = ops.zip(operators.lt)\n",
        "        self.eq_zip = ops.zip(operators.eq)\n",
        "        self.is_close_zip = ops.zip(operators.is_close)\n",
        "        self.relu_back_zip = ops.zip(operators.relu_back)\n",
        "        self.log_back_zip = ops.zip(operators.log_back)\n",
        "        self.inv_back_zip = ops.zip(operators.inv_back)\n",
        "\n",
        "        # Reduce\n",
        "        self.add_reduce = ops.reduce(operators.add, 0.0)\n",
        "        self.mul_reduce = ops.reduce(operators.mul, 1.0)\n",
        "\n",
        "        # Matrix Multiply\n",
        "        self.matrix_multiply = ops.matrix_multiply\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "F0KSoDe2Kwg4"
      },
      "outputs": [],
      "source": [
        "class CudaKernelOps(TensorOps):\n",
        "    @staticmethod\n",
        "    def map(fn: Callable[[float], float]) -> MapProto:\n",
        "        ### Your Implementation ###\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def zip(fn: Callable[[float, float], float]) -> Callable[[Tensor, Tensor], Tensor]:\n",
        "        ### Your Implementation ###\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def reduce(\n",
        "        fn: Callable[[float, float], float], start: float = 0.0\n",
        "    ) -> Callable[[Tensor, int], Tensor]:\n",
        "        ### Your Implementation ###\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def matrix_multiply(a: Tensor, b: Tensor) -> Tensor:\n",
        "        ### Your Implementation ###\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "uO7xsynCKwg4"
      },
      "outputs": [],
      "source": [
        "# In project/run_sentiment.py\n",
        "backend_name = \"CudaKernelOps\"\n",
        "\n",
        "if backend_name == \"CudaKernelOps\":\n",
        "    #from minitorch.cuda_kernel_ops import CudaKernelOps\n",
        "    BACKEND = minitorch.TensorBackend(CudaKernelOps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRqzdsHDKwg4"
      },
      "source": [
        "### Connect to CUDA Kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_lbjGHW4cDl",
        "outputId": "6a215d0c-593e-42fa-aae7-f5758905a5a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.2.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2025.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.6)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from mako->pycuda) (3.0.2)\n",
            "Downloading pytools-2025.1.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1.2-cp311-cp311-linux_x86_64.whl size=660362 sha256=1328ab5c10437cabc800b3c34d93cc91ae72f3df2d1ff69d9b5001a96c2e537f\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/66/50/c65e6116d7e0e16abe0f7c19b50327f76724ccfefbdc61a1b9\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.3.9 pycuda-2024.1.2 pytools-2025.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "jPMj418zKwg4"
      },
      "outputs": [],
      "source": [
        "import ctypes\n",
        "import pycuda.gpuarray as gpuarray\n",
        "import pycuda.driver as drv\n",
        "from pycuda.compiler import SourceModule\n",
        "import pycuda.autoinit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh7-UUUSKwg5",
        "outputId": "9e2a54b3-1906-4229-81ee-f241fd72eba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda kernels not implemented: combine.so not found\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    lib = ctypes.CDLL(\"minitorch/cuda_kernels/combine.so\")\n",
        "except:\n",
        "    print(\"cuda kernels not implemented: combine.so not found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knSho53n4ltO"
      },
      "source": [
        "Inside cuda_kernel_ops.py, we call cuda kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "b5wShSAxKwg5"
      },
      "outputs": [],
      "source": [
        "def map(fn: Callable[[float], float]) -> MapProto:\n",
        "    \"See `tensor_ops.py`\"\n",
        "    fn_id = fn_map[fn]\n",
        "\n",
        "    def ret(a: Tensor, out: Optional[Tensor] = None) -> Tensor:\n",
        "        if out is None:\n",
        "            out = a.zeros(a.shape)\n",
        "\n",
        "        # Define the argument type for the tensorMap function\n",
        "        lib.tensorMap.argtypes = [\n",
        "            ctypes.POINTER(ctypes.c_double),  # out\n",
        "            ctypes.POINTER(ctypes.c_int),    # out_shape\n",
        "            ctypes.POINTER(ctypes.c_int),    # out_strides\n",
        "            ctypes.c_int,                    # out_size\n",
        "            ctypes.POINTER(ctypes.c_double),  # in_storage\n",
        "            ctypes.POINTER(ctypes.c_int),    # in_shape\n",
        "            ctypes.POINTER(ctypes.c_int),    # in_strides\n",
        "            ctypes.c_int,                    # shape_len\n",
        "            ctypes.c_int,                    # fn_id\n",
        "        ]\n",
        "\n",
        "        # Define the return type for the tensorMap function\n",
        "        lib.tensorMap.restype = None\n",
        "\n",
        "        # Convert the numpy arrays to gpuarrays that can be loaded to the gpu\n",
        "        out_array_gpu = gpuarray.to_gpu(out._tensor._storage)\n",
        "        out_shape_gpu = gpuarray.to_gpu(out._tensor._shape.astype(np.int32))\n",
        "        out_strides_gpu = gpuarray.to_gpu(out._tensor._strides.astype(np.int32))\n",
        "        in_array_gpu = gpuarray.to_gpu(a._tensor._storage)\n",
        "        in_shape_gpu = gpuarray.to_gpu(a._tensor._shape.astype(np.int32))\n",
        "        in_strides_gpu = gpuarray.to_gpu(a._tensor._strides.astype(np.int32))\n",
        "\n",
        "\n",
        "        # Call the function\n",
        "        lib.tensorMap(\n",
        "            ctypes.cast(out_array_gpu.ptr, ctypes.POINTER(ctypes.c_double)),\n",
        "            ctypes.cast(out_shape_gpu.ptr, ctypes.POINTER(ctypes.c_int)),\n",
        "            ctypes.cast(out_strides_gpu.ptr, ctypes.POINTER(ctypes.c_int)),\n",
        "            ctypes.c_int(out.size),\n",
        "            ctypes.cast(in_array_gpu.ptr, ctypes.POINTER(ctypes.c_double)),\n",
        "            ctypes.cast(in_shape_gpu.ptr, ctypes.POINTER(ctypes.c_int)),\n",
        "            ctypes.cast(in_strides_gpu.ptr, ctypes.POINTER(ctypes.c_int)),\n",
        "            ctypes.c_int(len(a.shape)),\n",
        "            ctypes.c_int(fn_id)\n",
        "        )\n",
        "\n",
        "        # Copy the gpuarray back to the cpu\n",
        "        out._tensor._storage = out_array_gpu.get()\n",
        "\n",
        "        # Free the gpuarrays\n",
        "        out_array_gpu.gpudata.free()\n",
        "        out_shape_gpu.gpudata.free()\n",
        "        out_strides_gpu.gpudata.free()\n",
        "        in_array_gpu.gpudata.free()\n",
        "        in_shape_gpu.gpudata.free()\n",
        "        in_strides_gpu.gpudata.free()\n",
        "        return out\n",
        "\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU4Ahx1nKwg5"
      },
      "source": [
        "```c++\n",
        "    void tensorMap(\n",
        "        scalar_t* out,\n",
        "        int* out_shape,\n",
        "        int* out_strides,\n",
        "        int out_size,\n",
        "        scalar_t* in_storage,\n",
        "        int* in_shape,\n",
        "        int* in_strides,\n",
        "        int shape_size,\n",
        "        int fn_id\n",
        "    ) {\n",
        "        int threadsPerBlock = BASE_THREAD_NUM;\n",
        "        int blocksPerGrid = (out_size + threadsPerBlock - 1) / threadsPerBlock;\n",
        "        mapKernel<<<blocksPerGrid, threadsPerBlock>>>(out, out_shape, out_strides, out_size, in_storage, in_shape, in_strides, shape_size, fn_id);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOIi_tfGMbyn"
      },
      "source": [
        "## **MiniTorch Automatic Differentiation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ObLD2XlOMa-k"
      },
      "outputs": [],
      "source": [
        "from minitorch import SimpleBackend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcLYzqnRMjQ1"
      },
      "source": [
        "MiniTorch tensors are connect operations in the computational graph as described in last lecture.\n",
        "\n",
        "Note: this example uses SimpleBackend implemented in Python, which isn't nearly as good as your Cuda backend :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyC8EG7DM2Rp"
      },
      "source": [
        "Let's consider a simple example of $z = x * y$, the element-wise multiplication of two 1-d tensors.\n",
        "\n",
        "Suppose this happened somewhere in your Neural Network.\n",
        "\n",
        "During your backward pass, you've calculated your loss **$\\frac{\\partial loss}{\\partial z}$.**\n",
        "\n",
        "You want **$\\frac{\\partial loss}{\\partial x}$** and **$\\frac{\\partial loss}{\\partial y}$**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Xs5afN5MMpzO"
      },
      "outputs": [],
      "source": [
        "x = minitorch.tensor([1, 2, 3, 4, 5, 6], backend=SimpleBackend)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Hw4_uu78Mrd7"
      },
      "outputs": [],
      "source": [
        "x.requires_grad_(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v0nxjHkMsZE",
        "outputId": "bd87c649-cab9-4ffa-b3f2-6bc2f22ce1ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\n",
              "[1.000000 2.000000 3.000000 4.000000 5.000000 6.000000]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "KsxiG6qZMuLP"
      },
      "outputs": [],
      "source": [
        "y = minitorch.tensor([2, 4, 6, 8, 10, 12], backend=SimpleBackend)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "SLN44ySMMwhv"
      },
      "outputs": [],
      "source": [
        "y.requires_grad_(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGcml7r7MxYJ",
        "outputId": "245e7ecd-c17c-46e3-88b0-ae026398a0d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\n",
              "[2.000000 4.000000 6.000000 8.000000 10.000000 12.000000]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "MmGykxaHMyPK"
      },
      "outputs": [],
      "source": [
        "z = x * y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64Qc8cpqMzHU",
        "outputId": "bb8b2d1c-2453-4239-e609-c96fb4418365"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\n",
              "[2.000000 8.000000 18.000000 32.000000 50.000000 72.000000]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDFHOyK-Nwnv"
      },
      "source": [
        "**How does MiniTorch calculate the gradients for each tensor?**\n",
        "\n",
        "By using *reverse mode automatic differentiation* - let's examine how this is implemented in MiniTorch with the simple example above of\n",
        "\n",
        "`z = x * y`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htY91cdMNz-P"
      },
      "source": [
        "They contain important fields and methods for enabling automatic differentiation, including the\n",
        "* `self.f` field - tells us what backend we're using\n",
        "* `self.history` field - tracks the computation\n",
        "* `self.grad` field - stores the gradient for the optimizer\n",
        "* `chain_rule` method - lets us obtain partial adjoints for `backpropagate` to propagate from a node to its inputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RATsGxgN1z9"
      },
      "source": [
        "We are going to utilize the computation graph as a way to automatically compute derivatives of arbitrary python functions.\n",
        "\n",
        "The trick behind this autodifferentiation is to implement the derivative of each individual function, and then utilize the chain rule to compute a derivative for any scale value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRd7dFTiN4vO"
      },
      "source": [
        "**Let's examine the trace of the forward evaluation**\n",
        "to get a better idea of how `z` got computed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvduw9OZN8Mz"
      },
      "source": [
        "1. Open `minitorch/tensor.py:153` to find `__mul__`\n",
        "\n",
        "\n",
        "```python\n",
        "def __mul__(self, b: TensorLike) -> Tensor:\n",
        "        return Mul.apply(self, self._ensure_tensor(b))\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2oOIbMjN9cP"
      },
      "source": [
        "2. Open `minitorch/tensor_functions.py:99` to find\n",
        "```python\n",
        "class Mul(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx: Context, a: Tensor, b: Tensor) -> Tensor:\n",
        "        ctx.save_for_backward(a, b)\n",
        "        return a.f.mul_zip(a, b)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx: Context, grad_output: Tensor) -> Tuple[Tensor, Tensor]:\n",
        "        a, b = ctx.saved_values\n",
        "        return (\n",
        "            grad_output.f.mul_zip(b, grad_output),\n",
        "            grad_output.f.mul_zip(a, grad_output),\n",
        "        )\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCVoaPFLN__y"
      },
      "source": [
        "3. Open `minitorch/tensor_functions.py:33` to find\n",
        "\n",
        "```python\n",
        "class Function:\n",
        "    @classmethod\n",
        "    def _backward(cls, ctx: Context, grad_out: Tensor) -> Tuple[Tensor, ...]:\n",
        "        return wrap_tuple(cls.backward(ctx, grad_out))  # type: ignore\n",
        "\n",
        "    @classmethod\n",
        "    def _forward(cls, ctx: Context, *inps: Tensor) -> Tensor:\n",
        "        return cls.forward(ctx, *inps)  # type: ignore\n",
        "\n",
        "    @classmethod\n",
        "    def apply(cls, *vals: Tensor) -> Tensor:\n",
        "        raw_vals = []\n",
        "        need_grad = False\n",
        "        for v in vals:\n",
        "            if v.requires_grad():\n",
        "                need_grad = True\n",
        "            raw_vals.append(v.detach())\n",
        "\n",
        "        # Create the context.\n",
        "        ctx = Context(not need_grad)\n",
        "\n",
        "        # Call forward with the variables.\n",
        "        c = cls._forward(ctx, *raw_vals)\n",
        "        \n",
        "        back = None\n",
        "        if need_grad:\n",
        "            back = minitorch.History(cls, ctx, vals)\n",
        "        return minitorch.Tensor(c._tensor, back, backend=c.backend)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caVkjSbrODs_"
      },
      "source": [
        "\n",
        "So, we can see that Z is a new tensor with a **history**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xfBZ7PMOGC5"
      },
      "source": [
        "### **How do we get $\\frac{\\partial l}{\\partial x}$ and $\\frac{\\partial l}{\\partial y}$ given $\\frac{\\partial l}{\\partial z}$?**\n",
        "\n",
        "\n",
        "You've probably written this code in pytorch\n",
        "```python\n",
        "loss.sum().backward()\n",
        "```\n",
        "\n",
        "Since `loss.sum()` is still a tensor, you're calling the following method\n",
        "\n",
        "```python\n",
        "    def backward(self, grad_output: Optional[Tensor] = None) -> None:\n",
        "        if grad_output is None:\n",
        "            assert self.shape == (1,), \"Must provide grad_output if non-scalar\"\n",
        "            grad_output = Tensor.make([1.0], (1,), backend=self.backend)\n",
        "        backpropagate(self, grad_output)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S78EcRTuOJl2"
      },
      "source": [
        "\n",
        "You've reached a point in the graph you've constructed for the backward pass where you have the following gradient propagated back to $z$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "3XADUxquOJ0k"
      },
      "outputs": [],
      "source": [
        "dldz = minitorch.tensor([1, 1, 1, 1, 1, 1], backend=SimpleBackend)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNoqEQkjONVq"
      },
      "source": [
        "Let's make use of `z.history`, which tells us:\n",
        "1. The function used to calculate z\n",
        "2. The context ie. intermediate values we need to calculate the gradients of z's inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z54eaYtOL2s",
        "outputId": "03078540-e30c-4b5e-db30-64ee92f89caa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "History(last_fn=<class 'minitorch.tensor_functions.Mul'>, ctx=Context(no_grad=False, saved_values=(\n",
              "[1.000000 2.000000 3.000000 4.000000 5.000000 6.000000], \n",
              "[2.000000 4.000000 6.000000 8.000000 10.000000 12.000000])), inputs=(\n",
              "[1.000000 2.000000 3.000000 4.000000 5.000000 6.000000], \n",
              "[2.000000 4.000000 6.000000 8.000000 10.000000 12.000000]))"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z.history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr-cq8FNOQyy"
      },
      "source": [
        "In your `backpropagate` function, you should use the `chain_rule` method of a tensor in `minitorch/tensor.py:373`.\n",
        "\n",
        "```python\n",
        "    def chain_rule(self, d_output: Any) -> Iterable[Tuple[Variable, Any]]:\n",
        "        h = self.history\n",
        "        assert h is not None\n",
        "        assert h.last_fn is not None\n",
        "        assert h.ctx is not None\n",
        "\n",
        "        x = h.last_fn._backward(h.ctx, d_output)\n",
        "        assert len(x) == len(h.inputs), f\"Bug in function {h.last_fn}\"\n",
        "        return [\n",
        "            (inp, inp.expand(self._ensure_tensor(d_in)))\n",
        "            for inp, d_in in zip(h.inputs, x)\n",
        "        ]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiqjO9zdOPRi",
        "outputId": "af71ef05-2452-4bb4-d7bf-257ccbcb9e87"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "minitorch.tensor_functions.Mul"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z.history.last_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdPAjWIsOSaR",
        "outputId": "0bcdf13a-371f-4d80-cafe-d4e4b6f37fdf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Context(no_grad=False, saved_values=(\n",
              "[1.000000 2.000000 3.000000 4.000000 5.000000 6.000000], \n",
              "[2.000000 4.000000 6.000000 8.000000 10.000000 12.000000]))"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# saved_values == (x, y)\n",
        "z.history.ctx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aatjEeJxOYAX"
      },
      "source": [
        "If $z = x*y$ then $\\frac{\\partial l}{\\partial x} = \\frac{\\partial l}{\\partial z} \\frac{\\partial z}{\\partial x} = \\frac{\\partial l}{\\partial z} y$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zk1ink0Owjy"
      },
      "source": [
        "\n",
        "Open `minitorch/tensor_functions.py:99` to find\n",
        "```python\n",
        "class Mul(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx: Context, a: Tensor, b: Tensor) -> Tensor:\n",
        "        ctx.save_for_backward(a, b)\n",
        "        return a.f.mul_zip(a, b)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx: Context, grad_output: Tensor) -> Tuple[Tensor, Tensor]:\n",
        "        a, b = ctx.saved_values\n",
        "        return (\n",
        "            grad_output.f.mul_zip(b, grad_output),\n",
        "            grad_output.f.mul_zip(a, grad_output),\n",
        "        )\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "53FFiHhqOTXt"
      },
      "outputs": [],
      "source": [
        "# This is exactly what's happening in backward!\n",
        "dldx, dldy = z.history.last_fn._backward(z.history.ctx, dldz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sUs5ZZiOdyR"
      },
      "source": [
        "$\\frac{\\partial l}{\\partial x} = \\frac{\\partial l}{\\partial z} \\frac{\\partial z}{\\partial x} = \\frac{\\partial l}{\\partial z} y$\n",
        "```python\n",
        "dldx = tensor([1,1,1,1,1,1]) * tensor([2,4,6,8,10,12])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7emxjBhSOUkt",
        "outputId": "5863f70c-6d0f-40a9-852b-15959bc31cbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\n",
              "[2.000000 4.000000 6.000000 8.000000 10.000000 12.000000]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dldx # = dldz * y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlpUEUqiOgXu",
        "outputId": "cf35755b-78f1-4b17-fe47-669b1a42171e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\n",
              "[1.000000 1.000000 1.000000 1.000000 1.000000 1.000000]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(dldz * y) == dldx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6vmnIzUOhV1",
        "outputId": "fc8bc5c3-d2c1-4424-e255-e2bba6b1c8d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\n",
              "[1.000000 2.000000 3.000000 4.000000 5.000000 6.000000]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dldy # = dldz * x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvD4ddzIOiD9",
        "outputId": "1a3ef660-8cb6-40d3-aaa0-503e472f627e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\n",
              "[1.000000 1.000000 1.000000 1.000000 1.000000 1.000000]"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(dldz * x) == dldy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86o3hrUwOlT9"
      },
      "source": [
        "Defining functions in this way (Tensor in, Tensor out) is really powerful because it enables us to easily calculate the gradient of any python function that operates on Tensors eg. .sum(), .permute(), etc.\n",
        "\n",
        "There are many things to be careful of when shapes change eg.\n",
        "How do you calculate the gradient when you've done a `.sum(dim=2)`?\n",
        "\n",
        "Backpropagation vs. Reverse Mode Automatic Differentiation\n",
        "1. Modern deep learning frameworks don't use backpropagation on the forward computational graph.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "IYJbDGLrIK93",
        "gH9OYx-XJNGQ",
        "mWRAVR1kQSFS",
        "QE0eesQ04d-W",
        "xSo94QvzCFbn",
        "7sejR8-MTPmM",
        "RdCXpyn3j9e-"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "minitorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
